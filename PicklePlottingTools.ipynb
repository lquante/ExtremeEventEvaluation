{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: extend to multiple variables \n",
    "\n",
    "# Imports\n",
    "import pickle\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import numpy as np\n",
    "import iris\n",
    "from iris.analysis import Aggregator\n",
    "import iris.plot as iplt\n",
    "import iris.quickplot as qplt\n",
    "import iris.coord_categorisation\n",
    "from iris.util import rolling_window\n",
    "from ruamel import yaml\n",
    "from tqdm import tqdm\n",
    "from ruamel.yaml import ruamel\n",
    "import warnings\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set outputpath for plots etc\n",
    "\n",
    "outputdir = '/p/tmp/quante/snow_simulation_data/notebook_output'\n",
    "os.chdir(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load results data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filelist = ['/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "           ,'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "           , '/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "           ,'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "            ,'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "           ]\n",
    "results = []\n",
    "for i_file in filelist:\n",
    "    with open(i_file, 'rb') as stream:\n",
    "        results.append(pickle.load(stream))\n",
    "\n",
    "number_models=len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_results = dict(results [0])\n",
    "for i in range (1,number_models):\n",
    "    all_results.update(results[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load europe results data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eu_filelist = ['/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2021_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2021_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2021_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2021_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2021_3'\n",
    "]\n",
    "eu_results = []\n",
    "for i_file in eu_filelist:\n",
    "    with open(i_file, 'rb') as stream:\n",
    "        eu_results.append(pickle.load(stream))\n",
    "\n",
    "number_models=len(eu_results)\n",
    "\n",
    "eu_all_results = dict(eu_results [0])\n",
    "for i in range (1,number_models):\n",
    "    eu_all_results.update(eu_results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(all_results[('gfdl-esm4', 'preindustrial', 'NORTHERN AMERICA')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load midterm results data \n",
    "\n",
    "midterm_filelist = [\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2051_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2051_3']\n",
    "\n",
    "midterm__results = []\n",
    "for i_file in midterm_filelist:\n",
    "    with open(i_file, 'rb') as stream:\n",
    "        midterm__results.append(pickle.load(stream))\n",
    "\n",
    "number_models=len(midterm__results)\n",
    "\n",
    "midterm_all_results = dict(midterm__results [0])\n",
    "for i in range (1,number_models):\n",
    "    midterm_all_results.update(midterm__results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load longterm results data \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "longterm_filelist = [\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN EUROPE_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ukesm1-0-ll_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mpi-esm1-2-hr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/gfdl-esm4_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/ipsl-cm6a-lr_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2071_3',\n",
    "'/p/tmp/quante/snow_simulation_data/20200417_quantile_baseline_exceedance_data/mri-esm2-0_NORTHERN AMERICA_preindustrial_baseline_hist_from_1851ssp_from_2071_3']\n",
    "\n",
    "longterm__results = []\n",
    "for i_file in longterm_filelist:\n",
    "    with open(i_file, 'rb') as stream:\n",
    "        longterm__results.append(pickle.load(stream))\n",
    "\n",
    "number_models=len(longterm__results)\n",
    "\n",
    "longterm_all_results = dict(longterm__results [0])\n",
    "for i in range (1,number_models):\n",
    "    longterm_all_results.update(longterm__results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some plotting methods:\n",
    "\n",
    "# define colormap whitefilling 0 values\n",
    "\n",
    "colors_no_extreme = plt.cm.viridis(np.linspace(0, 0.05, 1))\n",
    "colors_extreme = plt.cm.viridis(np.linspace(0.1, 1, 20))\n",
    "all_colors = np.vstack((colors_no_extreme, colors_extreme))\n",
    "# make color value for 0 white\n",
    "all_colors[0] = (1, 1, 1, 1.0)\n",
    "\n",
    "extremes_cmap = clr.LinearSegmentedColormap.from_list('extremes_map',\n",
    "                                                                       all_colors)    \n",
    "colormap = plt.get_cmap(extremes_cmap,30)\n",
    "\n",
    "# plot map cubes:\n",
    "\n",
    "def plot_cube(cube,startyear,finalyear,threshold,vmin,vmax,label):\n",
    "    \n",
    "        pcm = iris.plot.pcolormesh(cube, cmap=extremes_cmap,vmin=vmin,vmax=vmax)\n",
    "        cbar = plt.colorbar(pcm, extend='both', orientation='horizontal',label=label)\n",
    "        \n",
    "        plt.title(str(startyear) + \" to \" + str(finalyear), fontsize=10)\n",
    "        plt.gca().coastlines()\n",
    "\n",
    "def plot_results_dict (results,key1,threshold):\n",
    "    keys = list(results[key1].keys())\n",
    "    fig = plt.figure(figsize=(15, 10)) \n",
    "    ax1 = plt.subplot(231)\n",
    "    plot_from_results_dict(results,key1,keys[0],threshold)\n",
    "    ax2 = plt.subplot(232)\n",
    "    plot_from_results_dict(results,key1,keys[1],threshold)\n",
    "    ax3 = plt.subplot(233)\n",
    "    plot_from_results_dict(results,key1,keys[2],threshold)\n",
    "\n",
    "    ax1 = plt.subplot(234)\n",
    "    plot_from_results_dict(results,key1,keys[3],threshold)\n",
    "    ax2 = plt.subplot(235)\n",
    "    plot_from_results_dict(results,key1,keys[4],threshold)\n",
    "    ax3 = plt.subplot(236)\n",
    "    plot_from_results_dict(results,key1,keys[5],threshold)\n",
    "\n",
    "    plt.show()\n",
    "    filename = str(key1)+\"_threshold_\"+str(threshold)\n",
    "    fig.savefig(filename+\".png\")\n",
    "    plt.close()  \n",
    "\n",
    "    \n",
    "import matplotlib.colors\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "def plot_difference_cube(cube,scenario_data,startyear_data,finalyear_data,scenario_comparison,startyear_comparison,finalyear_comparison,threshold,vmin,vmax,label):\n",
    "        \n",
    "    \n",
    "       \n",
    "        colormap = plt.get_cmap('RdBu_r',30)\n",
    "        ax = plt.axes(projection=cartopy.crs.PlateCarree())\n",
    "        \n",
    "        ax.add_feature(cartopy.feature.LAND, zorder=100, edgecolor='k')\n",
    "        ax.coastlines()\n",
    "        pcm = iris.plot.pcolormesh(cube, cmap=colormap,vmin=vmin,vmax=vmax)\n",
    "        \n",
    "        \n",
    "        cbar = plt.colorbar(pcm, extend='both', orientation='horizontal',label=label)\n",
    "        cbar.minorticks_on()\n",
    "        \n",
    "        plt.title(scenario_data+ \": \"+str(startyear_data) + \" to \" + str(finalyear_data) +\"\\n -\"+\n",
    "                  scenario_comparison+ \": \"+str(startyear_comparison) + \" to \" + str(finalyear_comparison), fontsize=10)\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "def plot_ratio_cube(cube,scenario_data,startyear_data,finalyear_data,scenario_comparison,startyear_comparison,finalyear_comparison,specification,label):\n",
    "\n",
    "\n",
    "\n",
    "        colormap = plt.get_cmap('RdBu_r',30)\n",
    "        ax = plt.axes(projection=cartopy.crs.PlateCarree())\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cartopy.feature.LAND, zorder=100, edgecolor='k')\n",
    "        \n",
    "        pcm = iris.plot.pcolormesh(cube, cmap=colormap,vmin=0,vmax=2)\n",
    "\n",
    "        cbar = plt.colorbar(pcm, extend='both', orientation='horizontal',label=label)\n",
    "        cbar.minorticks_on()\n",
    "        \n",
    "        plt.title(scenario_data+ \": \"+str(startyear_data) + \" to \" + str(finalyear_data) +\"\\n -\"+\n",
    "                  scenario_comparison+ \": \"+str(startyear_comparison) + \" to \" + str(finalyear_comparison), fontsize=10)\n",
    "       \n",
    "\n",
    "\n",
    "        \n",
    "def plot_difference_dict (datadict):\n",
    "    plot_difference_cube(datadict['cube'],datadict['scenario'],datadict['startyear'],datadict['finalyear_datadict'],\n",
    "    datadict['scenario_subtrahend'],datadict['startyear_subtrahend'],datadict['finalyear_subtrahend'],datadict['threshold'])\n",
    "    \n",
    "def difference_dict(data_key1,data_key2,threshold,\n",
    "                   subtrahend_key1,subtrahend_key2):\n",
    "    data = results[data_key1][data_key2]['map_cubes'][(str(threshold),'map')]\n",
    "    subtrahend = results[subtrahend_key1][subtrahend_key2]['map_cubes'][(str(threshold),'map')]\n",
    "    diffdict = {}\n",
    "    diffdict ['cube'] = data-subtrahend\n",
    "    diffdict['scenario'] =data_key2[0]\n",
    "    diffdict['startyear']=data_key2[1]\n",
    "    diffdict['finalyear_datadict']=data_key2[2]\n",
    "    diffdict['scenario_subtrahend']=subtrahend_key2[0]\n",
    "    diffdict['startyear_subtrahend']=subtrahend_key2[1]\n",
    "    diffdict['finalyear_subtrahend']=subtrahend_key2[2]\n",
    "    diffdict['threshold']=threshold\n",
    "    return diffdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get results for (model,comparisonname,region) triple:\n",
    "\n",
    "def specify_results (resultsdict,modelname,comparisonname,regionname,multimodel = True):\n",
    "    if multimodel:\n",
    "        output =  resultsdict [modelname,comparisonname,regionname]\n",
    "    else:\n",
    "        output = resultsdict [comparisonname,regionname]\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# routine to generate datasets for comparison between reference period and changing timeperiods:\n",
    "\n",
    "def data_collection (results,scenario,start_year,final_year,timeperiod_length):\n",
    "    data_timeperiod = final_year-start_year+1\n",
    "    number_of_timeperiods = data_timeperiod/timeperiod_length\n",
    "    reference_data = []\n",
    "   \n",
    "    for year in range(start_year,final_year,timeperiod_length):\n",
    "    \n",
    "        reference_data.append(results[scenario,year,year+timeperiod_length-1])\n",
    "       \n",
    "       \n",
    "    exceedance_arrays = []\n",
    "    intensity_arrays = []\n",
    "    maps = []\n",
    "    expected_snowfall_maps = []\n",
    "   \n",
    "    # prepare reference arrays\n",
    "    for i_reference_timeperiod in reference_data:\n",
    "        exceedance_arrays.append(i_reference_timeperiod['exceedance_array'][1])\n",
    "        intensity_arrays.append(i_reference_timeperiod['intensity_array'][1])\n",
    "        reference_thresholds = i_reference_timeperiod['intensity_array'][0]\n",
    "        maps.append(i_reference_timeperiod['map_cubes'])\n",
    "    \n",
    "    \n",
    "    intensity = np.sum(intensity_arrays,axis=0)\n",
    "    \n",
    "    exceedances = np.sum(exceedance_arrays,axis=0)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    reference_exceedances = np.vstack((reference_thresholds,exceedances))\n",
    "    reference_intensity = np.vstack((reference_thresholds,intensity))\n",
    "\n",
    "    # prepare reference cubes\n",
    "    dict_cubelists = {}\n",
    "    for i_key in (maps[0].keys()):\n",
    "        cubelist = iris.cube.CubeList()\n",
    "        for i_data in maps:\n",
    "            cubelist.append(i_data[i_key])\n",
    "        dict_cubelists[i_key] = cubelist\n",
    "    \n",
    "    reference_cubes = {}\n",
    "    for i_key in (dict_cubelists):\n",
    "        reference_cube = dict_cubelists[i_key][0]-dict_cubelists[i_key][0]\n",
    "        for i_cube in dict_cubelists[i_key]:\n",
    "            reference_cube += i_cube\n",
    "        reference_cubes[i_key]=reference_cube\n",
    "\n",
    "    for i_key in reference_cubes.keys():\n",
    "        reference_cubes[i_key]=reference_cubes[i_key]/number_of_timeperiods\n",
    "        \n",
    "     # prepare quantile cubes\n",
    "   \n",
    "  \n",
    "    reference_collection = {}\n",
    "    reference_collection ['exceedances'] = reference_exceedances\n",
    "    reference_collection ['intensity'] = reference_intensity\n",
    "    reference_collection ['cubes'] = reference_cubes\n",
    "    \n",
    "    return reference_collection\n",
    "\n",
    "def quantile_collection (results,scenario,start_year,final_year,timeperiod_length):\n",
    "    data_timeperiod = final_year-start_year+1\n",
    "    number_of_timeperiods = data_timeperiod/timeperiod_length\n",
    "    \n",
    "    quantile_data = []\n",
    "    for year in range(start_year,final_year,timeperiod_length):\n",
    "    \n",
    "       \n",
    "        quantile_data.append(results[scenario+'_quantile',year,year+timeperiod_length-1])\n",
    "    \n",
    "        \n",
    "     # prepare quantile cubes\n",
    "    quantile_cubelists = {}\n",
    "    \n",
    "    for i_key in (quantile_data[0].keys()):\n",
    "        cubelist = iris.cube.CubeList()\n",
    "        for i_data in quantile_data:\n",
    "            cubelist.append(i_data[i_key])\n",
    "        quantile_cubelists[i_key] = cubelist\n",
    "\n",
    "    quantile_cubes = {}\n",
    "    for i_key in (quantile_cubelists):\n",
    "       \n",
    "        if((quantile_cubelists[i_key][0].coord_dims('time')==(0,))):\n",
    "            reference_cube = (quantile_cubelists[i_key]).concatenate_cube()\n",
    "        else:\n",
    "            reference_cube = quantile_cubelists[i_key][0]-quantile_cubelists[i_key][0]\n",
    "            for i_cube in quantile_cubelists[i_key]:\n",
    "                reference_cube += i_cube\n",
    "        quantile_cubes[i_key]=reference_cube\n",
    "\n",
    "    for i_key in quantile_cubelists.keys():\n",
    "        if((quantile_cubelists[i_key][0].coord_dims('time')==(0,))):\n",
    "            quantile_cubes[i_key] = quantile_cubes[i_key]\n",
    "        else:\n",
    "            quantile_cubes[i_key]=quantile_cubes[i_key]/number_of_timeperiods    \n",
    "    reference_collection = {}    \n",
    "    reference_collection ['quantiles'] = quantile_cubes\n",
    "    return reference_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# routine to compare data from two reference scenarios:\n",
    "\n",
    "\n",
    "def plot_data(data,format,color,label=''):\n",
    "    thresholds = data [0]\n",
    "    exceedances = data [1]\n",
    "    plot = plt.plot(thresholds,exceedances,format,color=color,label=label)\n",
    "    # zero line\n",
    "    plt.axhline(linewidth=1)\n",
    "\n",
    "def calculate_mean_excess_array(intensity_data,exceedance_data):\n",
    "    mean = intensity_data[1]/exceedance_data[1]\n",
    "    thresholds = intensity_data[0]\n",
    "    excess_above_threshold_mean = mean-thresholds\n",
    "    return np.vstack((thresholds,excess_above_threshold_mean))\n",
    "\n",
    "def plot_timeframe_scenario (data,format,start,end,color,label=''):  \n",
    "    plot_data (data,format,color,label=label)\n",
    "    plt.title(str(start)+\" to \"+str(end))\n",
    "    return data\n",
    "\n",
    "def calculate_weighted_difference (data,subtrahend,subtrahend_weighting_factor):\n",
    "    difference = data[1]-subtrahend[1]*subtrahend_weighting_factor\n",
    "    thresholds =  data[0]\n",
    "    return np.vstack((thresholds,difference))\n",
    "\n",
    "def compare_timespans_threshold_frequency (modellist,results,scenario,start_year,final_year,timeperiod_length,reference_scenario,reference_start_year,reference_final_year,modelname,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = data_collection(results[i_model],reference_scenario,reference_start_year,reference_final_year,timeperiod_length)\n",
    "        data [i_model] = data_collection(results[i_model],scenario,start_year,final_year,timeperiod_length)\n",
    "    \n",
    "    reference_timelength= (reference_final_year-reference_start_year+1)\n",
    "    data_timelength=  (final_year-start_year+1)\n",
    "    # NB timeperiod length should be equal\n",
    "    data_weighting_factor = data_timelength/timeperiod_length\n",
    "    reference_weighting_factor = reference_timelength / timeperiod_length\n",
    "    reference_color = {}\n",
    "    data_color = {}\n",
    "    comparison_color = {}\n",
    "    color = {}\n",
    "    color['gfdl-esm4'] = 'navy'\n",
    "    color ['ipsl-cm6a-lr'] = 'darkred'\n",
    "    color ['mpi-esm1-2-hr'] = 'steelblue'\n",
    "    color ['mri-esm2-0'] ='deeppink'\n",
    "    color ['ukesm1-0-ll'] = 'darkorange'\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        \n",
    "        reference_color [i_model]  = color[i_model]\n",
    "    \n",
    "        data_color [i_model] = color[i_model]\n",
    "    \n",
    "        comparison_color [i_model] = color[i_model]\n",
    "    \n",
    "    \n",
    "    label_frequency = \"y = Number of days with daily snowfall >x\"\n",
    "    label_expected_snowfall = \"y= average for all snowfall>x  of (daily snowfall-x) (mm) \"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "  \n",
    "    suptitle = str(modelname)+' - '+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > threshold events'\n",
    "    \n",
    "    ax1 = plt.subplot(231)\n",
    "    # weight with scaling factor\n",
    "    weighted_reference_exceedances_thresholds = {}\n",
    "    weighted_data_exceedances_thresholds = {}\n",
    "    for i_model in modellist:\n",
    "        weighted_reference_exceedances = reference_data[i_model]['exceedances'][1]/reference_weighting_factor\n",
    "        weighted_reference_exceedances_thresholds[i_model] = np.vstack((reference_data[i_model]['exceedances'][0],weighted_reference_exceedances))\n",
    "        plot_timeframe_scenario (weighted_reference_exceedances_thresholds[i_model],'',reference_start_year, reference_final_year,reference_color[i_model],label=i_model)\n",
    "    plt.xlabel (label_frequency)\n",
    "    plt.title ('Decadal average from '+str(reference_start_year)+' to '+str(reference_final_year))\n",
    "    plt.legend(loc='best')\n",
    "    plt.suptitle(suptitle)\n",
    "    \n",
    "    \n",
    "    ax2 = plt.subplot(232,sharex=ax1, sharey=ax1)\n",
    "    for i_model in modellist:\n",
    "        weighted_data_exceedances = data[i_model]['exceedances'][1]/data_weighting_factor\n",
    "        weighted_data_exceedances_thresholds [i_model] = np.vstack((data[i_model]['exceedances'][0],weighted_data_exceedances))\n",
    "        plot_timeframe_scenario (weighted_data_exceedances_thresholds[i_model],'',start_year,final_year,data_color[i_model],label=i_model)\n",
    "    plt.title ('Decadal average from '+str(start_year)+' to '+str(final_year))\n",
    "    plt.xlabel (label_frequency)\n",
    "    plt.legend(loc='best')\n",
    "    ax3 = plt.subplot(233)\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        difference_data = calculate_weighted_difference (weighted_data_exceedances_thresholds[i_model],weighted_reference_exceedances_thresholds[i_model],1)\n",
    "        plot_data (difference_data,'',comparison_color [i_model],label = i_model)\n",
    "    \n",
    "    plt.title ('Difference of average '+scenario+'-'+reference_scenario)\n",
    "    plt.xlabel (label_frequency)\n",
    "    plt.legend(loc='best')\n",
    "    ax4 = plt.subplot(234)\n",
    "    reference_expected_snowfall ={}\n",
    "    for i_model in modellist:\n",
    "        reference_expected_snowfall[i_model]  = calculate_mean_excess_array (reference_data[i_model]['intensity'],reference_data[i_model]['exceedances'])  \n",
    "        plot_timeframe_scenario (reference_expected_snowfall[i_model],'',reference_start_year, reference_final_year,reference_color[i_model],i_model)\n",
    "    plt.title ('Average excess of threshold, '+reference_scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "    ax5 = plt.subplot(235,sharex=ax4, sharey=ax4)\n",
    "    expected_snowfall = {}\n",
    "    for i_model in modellist:\n",
    "        expected_snowfall[i_model] = calculate_mean_excess_array (data[i_model]['intensity'],data[i_model]['exceedances']) \n",
    "        plot_timeframe_scenario (expected_snowfall[i_model],'',start_year,final_year,data_color[i_model],i_model)\n",
    "    plt.title ('Average excess of threshold, '+scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "    ax6 = plt.subplot(236)\n",
    "    for i_model in modellist:                                                                                         \n",
    "        difference_data = calculate_weighted_difference (expected_snowfall[i_model],reference_expected_snowfall[i_model],1)\n",
    "        plot_data (difference_data,'',comparison_color[i_model],i_model)\n",
    "    plt.title ('Difference of '+scenario+'-'+reference_scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "   \n",
    "    \n",
    "\n",
    "   \n",
    "    filename = 'threshold_exceedance_analysis_'+str(modelname)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    " \n",
    "    plt.savefig(filename+'.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "    # method to compare map plots\n",
    "    \n",
    "def compare_timespans_threshold_maps (threshold,modellist,results,scenario,start_year,final_year,\n",
    "                                      timeperiod_length,reference_scenario,reference_start_year,\n",
    "                                      reference_final_year,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = data_collection(results[i_model],\n",
    "                                                   reference_scenario,reference_start_year,\n",
    "                                                   reference_final_year,timeperiod_length)\n",
    "        data [i_model] = data_collection(results[i_model],scenario,start_year,final_year,\n",
    "                                         timeperiod_length)\n",
    "        plot_model_maps (threshold,reference_data [i_model],data [i_model],\n",
    "                         scenario,start_year,final_year,\n",
    "                         reference_scenario,reference_start_year,reference_final_year,\n",
    "                         i_model,areaname)\n",
    "\n",
    "def plot_model_maps(threshold,reference_data,data,scenario,start_year,final_year\n",
    "                ,reference_scenario,reference_start_year,reference_final_year,modelname,areaname):\n",
    "    freq_key= 'frequency'\n",
    "    es_key= 'expected_snowfall'\n",
    "\n",
    "    reference_frequency=reference_data['cubes'][(str(threshold),freq_key)]\n",
    "    reference_expected_snowfall=reference_data['cubes'][(str(threshold),es_key)]\n",
    "    data_frequency=data['cubes'][(str(threshold),freq_key)]\n",
    "    data_expected_snowfall=data['cubes'][(str(threshold),es_key)]\n",
    "    difference_frequency = data_frequency-reference_frequency\n",
    "    difference_expected_snowfall = data_expected_snowfall-reference_expected_snowfall\n",
    "\n",
    "    vmin_frequency = 0\n",
    "    vmax_frequency = 30\n",
    "\n",
    "    vmin_freq_diff = -15\n",
    "    vmax_freq_diff = 15\n",
    "\n",
    "    label_frequency = 'decadal average number of days with snowfall >'+str(threshold)+\"mm\"\n",
    "    label_frequency_diff = 'difference of decadal average of days with snowfall >'+str(threshold)+\"mm\"\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "    suptitle = str(modelname)+' - '+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > threshold events'\n",
    "\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    ax1 = plt.subplot(231)\n",
    "    plot_cube(reference_frequency,reference_start_year,reference_final_year,threshold,vmin_frequency,vmax_frequency,label_frequency)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax2 = plt.subplot(232)\n",
    "    plot_cube(data_frequency,start_year,final_year,threshold,vmin_frequency,vmax_frequency,label_frequency)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "    ax3 = plt.subplot(233)\n",
    "\n",
    "    plot_difference_cube(difference_frequency,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,threshold,vmin_freq_diff,vmax_freq_diff,label_frequency_diff)\n",
    "\n",
    "\n",
    "    vmin_es = 0\n",
    "    vmax_es = 500\n",
    "\n",
    "    vmin_es_diff = -250\n",
    "    vmax_es_diff = 250\n",
    "\n",
    "    label_es = 'decadal average threshold excess of snowfall >'+str(threshold)+\"mm\"\n",
    "    label_es_diff = 'difference of decadal average threshold excess of snowfall >'+str(threshold)+\"mm\"\n",
    "    ax4 = plt.subplot(234)\n",
    "    plot_cube(reference_expected_snowfall,reference_start_year,reference_final_year,threshold,vmin_es,vmax_es,label_es)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax5 = plt.subplot(235)\n",
    "    plot_cube(data_expected_snowfall,start_year,final_year,threshold,vmin_es,vmax_es,label_es)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "\n",
    "    ax6 = plt.subplot(236)\n",
    "    plot_difference_cube(difference_expected_snowfall,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,threshold,vmin_es_diff,vmax_es_diff,label_es_diff)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = 'threshold_exceedance_maps_'+str(threshold)+'_'+str(modelname)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    "\n",
    "    plt.savefig(filename+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    #%%\n",
    "\n",
    "def compare_quantile_maps (quantile,modellist,results,scenario,start_year,final_year,\n",
    "                                      timeperiod_length,reference_scenario,reference_start_year,\n",
    "                                      reference_final_year,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = quantile_collection(results[i_model],\n",
    "                                                   reference_scenario,reference_start_year,\n",
    "                                                   reference_final_year,timeperiod_length)\n",
    "        data [i_model] = quantile_collection(results[i_model],scenario,start_year,final_year,\n",
    "                                         timeperiod_length)\n",
    "        plot_quantile_maps (quantile,reference_data [i_model],data [i_model],\n",
    "                         scenario,start_year,final_year,\n",
    "                         reference_scenario,reference_start_year,reference_final_year,\n",
    "                         i_model,areaname)    \n",
    "    \n",
    "def plot_quantile_maps(quantile,reference_data,data,scenario,start_year,final_year\n",
    "                ,reference_scenario,reference_start_year,reference_final_year,modelname,areaname):\n",
    "    quantile_key= 'quantile'\n",
    "    quantile_exceedance= 'mean_exceedance'\n",
    "\n",
    "    \n",
    "    ref_quantile=reference_data['quantiles'][quantile_key,quantile]\n",
    "    ref_expected_snowfall=reference_data['quantiles'][quantile_exceedance,quantile]\n",
    "    quantile_cube=data['quantiles'][quantile_key,quantile]\n",
    "    expected_snowfall=data['quantiles'][(quantile_exceedance,quantile)]\n",
    "    diff_quantiles = quantile_cube-ref_quantile\n",
    "    difference_expected_snowfall = expected_snowfall-ref_expected_snowfall\n",
    "    \n",
    "    \n",
    "    vmin_quantile = min(np.min(ref_quantile.data),np.min(quantile_cube.data))\n",
    "    vmax_quantile = max(np.max(ref_quantile.data),np.max(quantile_cube.data))\n",
    "\n",
    "    abs_value_min_diff = min (abs(np.min(diff_quantiles.data)),np.max(diff_quantiles.data))\n",
    "    \n",
    "    vmin_quantile_diff = -abs_value_min_diff\n",
    "    vmax_quantile_diff = abs_value_min_diff\n",
    "\n",
    "    label_frequency = 'decadal '+str(quantile)+\" percentile of daily snowfall (mm)\"\n",
    "    label_frequency_diff = 'difference of decadal '+str(quantile)+' percentile of daily snowfall (mm)'\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "    suptitle = str(modelname)+' - '+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > '+str(quantile)+'percentile'\n",
    "\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    ax1 = plt.subplot(231)\n",
    "    plot_cube(ref_quantile,reference_start_year,reference_final_year,quantile,vmin_quantile,vmax_quantile,label_frequency)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax2 = plt.subplot(232)\n",
    "    plot_cube(quantile_cube,start_year,final_year,quantile,vmin_quantile,vmax_quantile,label_frequency)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "    ax3 = plt.subplot(233)\n",
    "\n",
    "    plot_difference_cube(diff_quantiles,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_quantile_diff,vmax_quantile_diff,label_frequency_diff)\n",
    "\n",
    "\n",
    "\n",
    "    vmin_quantile_exceedance = min(np.min(ref_expected_snowfall.data),np.min(expected_snowfall.data))\n",
    "    vmax_quantile_exceedance = max(np.max(ref_expected_snowfall.data),np.max(expected_snowfall.data))\n",
    "\n",
    "    abs_value_min_diff_es = min (abs(np.min(difference_expected_snowfall.data)),np.max(difference_expected_snowfall.data))\n",
    "    \n",
    "    vmin_qe_diff = -abs_value_min_diff_es\n",
    "    vmax_qe_diff = abs_value_min_diff_es\n",
    "    \n",
    "\n",
    "    label_es = 'decadal average quantile excess of snowfall >'+str(quantile)+\"mm\"\n",
    "    label_es_diff = 'difference of decadal average quantile excess of snowfall >'+str(quantile)+\"mm\"\n",
    "    ax4 = plt.subplot(234)\n",
    "    plot_cube(ref_expected_snowfall,reference_start_year,reference_final_year,quantile,vmin_quantile_exceedance,vmax_quantile_exceedance,label_es)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax5 = plt.subplot(235)\n",
    "    plot_cube(expected_snowfall,start_year,final_year,quantile,vmin_quantile_exceedance,vmax_quantile_exceedance,label_es)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "\n",
    "    ax6 = plt.subplot(236)\n",
    "    plot_difference_cube(difference_expected_snowfall,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_qe_diff,vmax_qe_diff,label_es_diff)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = 'quantile_exceedance_maps_'+str(quantile)+'_'+str(modelname)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    "\n",
    "    plt.savefig(filename+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def lan_lot_mean(cube):\n",
    "    return cube.collapsed(('latitude','longitude'),iris.analysis.MEAN).data\n",
    "\n",
    "def compare_timespans_quantiles (modellist,quantiles,results,scenario,start_year,final_year,timeperiod_length,reference_scenario,reference_start_year,reference_final_year,modelname,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    quantile_key= 'quantile'\n",
    "    quantile_exceedance= 'mean_exceedance'\n",
    "    ref_quantile = {}\n",
    "    ref_expected_snowfall = {}\n",
    "    data_quantile = {}\n",
    "    expected_snowfall = {}\n",
    "    diff_quantiles = {}\n",
    "    diff_expected_snowfall={}\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = data_collection(results[i_model],reference_scenario,reference_start_year,reference_final_year,timeperiod_length)\n",
    "        data [i_model] = data_collection(results[i_model],scenario,start_year,final_year,timeperiod_length)\n",
    "     \n",
    "        for i_quantile in quantiles:\n",
    "            ref_quantile [i_model,i_quantile] =lan_lot_mean(reference_data[i_model]['quantiles'][quantile_key,i_quantile])\n",
    "            ref_expected_snowfall [i_model,i_quantile] =lan_lot_mean(reference_data[i_model]['quantiles'][quantile_exceedance,i_quantile])\n",
    "            data_quantile [i_model,i_quantile] =lan_lot_mean(data[i_model]['quantiles'][quantile_key,i_quantile])\n",
    "            expected_snowfall [i_model,i_quantile] =lan_lot_mean(data[i_model]['quantiles'][(quantile_exceedance,i_quantile)])\n",
    "            diff_quantiles[i_model,i_quantile] = (data_quantile[i_model,i_quantile]-ref_quantile[i_model,i_quantile])\n",
    "            diff_expected_snowfall[i_model,i_quantile] = (expected_snowfall[i_model,i_quantile]-ref_expected_snowfall[i_model,i_quantile])\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    reference_timelength= (reference_final_year-reference_start_year+1)\n",
    "    data_timelength=  (final_year-start_year+1)\n",
    "    # NB timeperiod length should be equal\n",
    "    data_weighting_factor = data_timelength/timeperiod_length\n",
    "    reference_weighting_factor = reference_timelength / timeperiod_length\n",
    "    reference_color = {}\n",
    "    data_color = {}\n",
    "    comparison_color = {}\n",
    "    color = {}\n",
    "    color['gfdl-esm4'] = 'navy'\n",
    "    color ['ipsl-cm6a-lr'] = 'darkred'\n",
    "    color ['mpi-esm1-2-hr'] = 'steelblue'\n",
    "    color ['mri-esm2-0'] ='deeppink'\n",
    "    color ['ukesm1-0-ll'] = 'darkorange'\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        \n",
    "        reference_color [i_model]  = color[i_model]\n",
    "    \n",
    "        data_color [i_model] = color[i_model]\n",
    "    \n",
    "        comparison_color [i_model] = color[i_model]\n",
    "    \n",
    "    \n",
    "    label_quantiles = \"y = area average of percentile (x) of daily snowfall (mm)\"\n",
    "    label_expected_snowfall = \"y= average for snowfall > percentile (x)  of (daily snowfall - percentile(x) (mm) \"\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "  \n",
    "    suptitle = str(modelname)+' - '+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > threshold events'\n",
    "    \n",
    "    ax1 = plt.subplot(231,xlim=(np.min(quantiles)-1,100))\n",
    "  \n",
    "    for i_model in modellist:\n",
    "        tupel = np.hstack((quantiles[0],ref_quantile [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model],label=i_model)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,ref_quantile [i_model,i_quantile]))\n",
    "            \n",
    "            plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model])\n",
    "            plt.axhline(linewidth=1)\n",
    "    plt.xlabel (label_quantiles)\n",
    "    plt.title (' '+str(reference_start_year)+' to '+str(reference_final_year))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.suptitle(suptitle)\n",
    "    \n",
    "    \n",
    "    ax2 = plt.subplot(232,sharex=ax1, sharey=ax1)\n",
    "    for i_model in modellist:\n",
    "        tupel = np.hstack((quantiles[0],data_quantile [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model],label=i_model)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,data_quantile [i_model,i_quantile]))\n",
    "            \n",
    "            plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model])\n",
    "            plt.axhline(linewidth=1)\n",
    "    plt.title (' '+str(start_year)+' to '+str(final_year))\n",
    "    plt.xlabel (label_quantiles)\n",
    "    plt.legend(loc='upper left')\n",
    "    ax3 = plt.subplot(233)\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        tupel = np.hstack((quantiles[0],data_quantile [i_model,quantiles[0]]-ref_quantile [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model],label=i_model)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,data_quantile [i_model,i_quantile]-ref_quantile [i_model,i_quantile]))\n",
    "            \n",
    "            plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model])\n",
    "            plt.axhline(linewidth=1)\n",
    "    plt.title ('Difference of  '+scenario+'-'+reference_scenario)\n",
    "    plt.xlabel (label_quantiles)\n",
    "    plt.legend(loc='best')\n",
    "    ax4 = plt.subplot(234)\n",
    "    reference_expected_snowfall ={}\n",
    "    for i_model in modellist:\n",
    "        tupel = np.hstack((quantiles[0],ref_expected_snowfall [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model],label=i_model)\n",
    "        plt.axhline(linewidth=1)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,ref_expected_snowfall [i_model,i_quantile]))\n",
    "            plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model])\n",
    "    plt.title ('Average excess of threshold, '+reference_scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "    ax5 = plt.subplot(235,sharex=ax4, sharey=ax4)\n",
    "   \n",
    "    for i_model in modellist:\n",
    "        tupel = np.hstack((quantiles[0],expected_snowfall [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model],label=i_model)\n",
    "        plt.axhline(linewidth=1)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,expected_snowfall [i_model,i_quantile]))\n",
    "            plt.plot (tupel[0],tupel[1],'.',color=data_color[i_model])\n",
    "    plt.title ('Average excess of threshold, '+scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "    ax6 = plt.subplot(236)\n",
    "    for i_model in modellist:                                                                                         \n",
    "        tupel = np.hstack((quantiles[0],expected_snowfall [i_model,quantiles[0]]-ref_expected_snowfall [i_model,quantiles[0]]))\n",
    "        plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model],label=i_model)\n",
    "        plt.axhline(linewidth=1)\n",
    "        for i_quantile in quantiles:\n",
    "            tupel = np.hstack((i_quantile,expected_snowfall [i_model,i_quantile]-ref_expected_snowfall [i_model,i_quantile]))\n",
    "            plt.plot (tupel[0],tupel[1],'.',color=reference_color[i_model])\n",
    "    plt.title ('Difference of '+scenario+'-'+reference_scenario)\n",
    "    plt.xlabel (label_expected_snowfall)\n",
    "    plt.legend(loc='best')\n",
    "   \n",
    "    \n",
    "\n",
    "   \n",
    "    filename = 'quantile_analysis_'+str(modelname)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    " \n",
    "    plt.savefig(filename+'.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def compare_quantile_baseline (quantile,modellist,results,scenario,start_year,final_year,\n",
    "                                      timeperiod_length,reference_scenario,reference_start_year,\n",
    "                                      reference_final_year,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = quantile_collection(results[i_model],\n",
    "                                                   reference_scenario,reference_start_year,\n",
    "                                                   reference_final_year,timeperiod_length)\n",
    "        data [i_model] = quantile_collection(results[i_model],scenario,start_year,final_year,\n",
    "                                         timeperiod_length)\n",
    "        plot_quantile_baseline (quantile,reference_data [i_model],data [i_model],\n",
    "                         scenario,start_year,final_year,\n",
    "                         reference_scenario,reference_start_year,reference_final_year,\n",
    "                         i_model,areaname)    \n",
    "    \n",
    "def plot_quantile_baseline (quantile,reference_data,data,scenario,start_year,final_year\n",
    "                ,reference_scenario,reference_start_year,reference_final_year,modelname,areaname):\n",
    "    baseline_key=\"quantile_baseline\"\n",
    "    frequency_key= 'number_exceedances'\n",
    "    exceedance_key= 'mean_exceedance'\n",
    "\n",
    "    baseline=reference_data['quantiles'][baseline_key,quantile]\n",
    "    ref_frequency = reference_data['quantiles'][frequency_key,quantile]\n",
    "    ref_expected_snowfall=reference_data['quantiles'][exceedance_key,quantile]\n",
    "    data_frequency = data['quantiles'][frequency_key,quantile]\n",
    "    data_expected_snowfall=data['quantiles'][exceedance_key,quantile]\n",
    "    diff_frequency = data_frequency-ref_frequency\n",
    "    diff_expected_snowfall = data_expected_snowfall-ref_expected_snowfall\n",
    "    \n",
    "    \n",
    "    vmin_base = 0\n",
    "    vmax_base = np.max(baseline.data) \n",
    "    label_baseline = str(quantile)+\" percentile of daily snowfall (mm)\"\n",
    "    \n",
    "    vmin_freq = 0\n",
    "    vmax_freq = max(np.max(ref_frequency.data),np.max(data_frequency.data))\n",
    "    \n",
    "    vmin_es = 0\n",
    "    vmax_es = max(np.max(ref_expected_snowfall.data),np.max(data_expected_snowfall.data))\n",
    "    \n",
    "    abs_value_freq_diff = max(abs(np.min(diff_frequency.data)),np.max(diff_frequency.data))\n",
    "    vmin_freq_diff = -abs_value_freq_diff\n",
    "    vmax_freq_diff = abs_value_freq_diff\n",
    "    \n",
    "    abs_value_es_diff = max(abs(np.min(diff_expected_snowfall.data)),np.max(diff_expected_snowfall.data))/2\n",
    "    vmin_es_diff = -abs_value_es_diff\n",
    "    vmax_es_diff = abs_value_es_diff\n",
    "\n",
    "    label_frequency = 'days with daily snowfall > baseline'\n",
    "    label_frequency_diff = 'difference of '+label_frequency \n",
    "    fig, fig_axs = plt.subplots(ncols=4, nrows=2,figsize=(20,8))\n",
    "    gs = fig_axs[0, 0].get_gridspec()\n",
    "    # remove the underlying axes\n",
    "    for i in range(0,4):\n",
    "        for ax in fig_axs[0:, i]:\n",
    "            ax.remove()\n",
    "   \n",
    "    \n",
    "    suptitle = str(modelname)+' - '+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > \\n baseline '+str(quantile)+' percentile'\n",
    "\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "    \n",
    "    ax0 = fig.add_subplot(gs[0:, 0])\n",
    "    plot_cube(baseline,1851,1880,quantile,vmin_base,vmax_base,label_baseline)\n",
    "    plt.title('baseline '+str(quantile)+' percentile (historical, 1851-1880)')\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    plot_cube(ref_frequency,reference_start_year,reference_final_year,quantile,vmin_freq,vmax_freq,label_frequency)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    plot_cube(data_frequency,start_year,final_year,quantile,vmin_freq,vmax_freq,label_frequency)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "    ax3 = fig.add_subplot(gs[0, 3])\n",
    "\n",
    "    plot_difference_cube(diff_frequency,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_freq_diff,vmax_freq_diff,label_frequency_diff)\n",
    "    \n",
    "\n",
    "    label_es = 'expected excess snowfall > baseline (mm)'\n",
    "    label_es_diff = 'difference of '+label_es\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    plot_cube(ref_expected_snowfall,reference_start_year,reference_final_year,quantile,vmin_es,vmax_es,label_es)\n",
    "    plt.title(reference_scenario+\" \"+str(reference_start_year) + \" to \" + str(reference_final_year), fontsize=10)\n",
    "    ax5 = fig.add_subplot(gs[1, 2])\n",
    "    plot_cube(data_expected_snowfall,start_year,final_year,quantile,vmin_es,vmax_es,label_es)\n",
    "    plt.title(scenario+\" \"+str(start_year) + \" to \" + str(final_year), fontsize=10)\n",
    "\n",
    "    ax6 = fig.add_subplot(gs[1, 3])\n",
    "    plot_difference_cube(diff_expected_snowfall,scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_es_diff,vmax_es_diff,label_es_diff)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = 'quantile_baseline_maps_'+str(quantile)+'_'+str(modelname)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    "\n",
    "    plt.savefig(filename+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def ensemble_quantile_baseline (quantile,modellist,results,scenario,start_year,final_year,\n",
    "                                      timeperiod_length,reference_scenario,reference_start_year,\n",
    "                                      reference_final_year,areaname):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    baseline = {}\n",
    "    ref_frequency = {}\n",
    "    ref_expected_snowfall = {}\n",
    "    data_frequency= {}\n",
    "    data_expected_snowfall= {}\n",
    "    diff_frequency= {}\n",
    "    diff_expected_snowfall= {}\n",
    "    \n",
    "    number_of_models = len(modellist)\n",
    "    \n",
    "    baseline_key=\"quantile_baseline\"\n",
    "    frequency_key= 'number_exceedances'\n",
    "    exceedance_key= 'mean_exceedance'\n",
    "      \n",
    "    label_baseline = str(quantile)+\" percentile of daily snowfall (mm)\"\n",
    "    \n",
    "    \n",
    "    vmin_base = 0\n",
    "    vmax_base = 0\n",
    "    \n",
    "    abs_value_freq_diff = 0\n",
    "    \n",
    "    abs_value_es_diff = 0\n",
    "    \n",
    "    for i_model in modellist:\n",
    "        reference_data [i_model] = quantile_collection(results[i_model],\n",
    "                                                   reference_scenario,reference_start_year,\n",
    "                                                   reference_final_year,timeperiod_length)\n",
    "        data [i_model] = quantile_collection(results[i_model],scenario,start_year,final_year,\n",
    "                                         timeperiod_length)\n",
    "        baseline [i_model]=reference_data[i_model]['quantiles'][baseline_key,quantile]\n",
    "        ref_frequency [i_model] = reference_data[i_model]['quantiles'][frequency_key,quantile]\n",
    "        ref_expected_snowfall [i_model]=reference_data[i_model]['quantiles'][exceedance_key,quantile]\n",
    "        data_frequency [i_model] = data[i_model]['quantiles'][frequency_key,quantile]\n",
    "        data_expected_snowfall [i_model]=data[i_model]['quantiles'][exceedance_key,quantile]\n",
    "        diff_frequency [i_model] = data_frequency[i_model]-ref_frequency[i_model]\n",
    "        diff_expected_snowfall [i_model] = data_expected_snowfall[i_model]-ref_expected_snowfall[i_model]\n",
    "\n",
    "        vmax_base = max(vmax_base,np.max(baseline [i_model].data) ) /2\n",
    "   \n",
    "        abs_value_freq_diff = max(abs_value_freq_diff\n",
    "                                  ,max(abs(np.min(diff_frequency[i_model].data)),\n",
    "                                       abs(np.max(diff_frequency[i_model].data)))\n",
    "                                 )\n",
    "    \n",
    "        abs_value_es_diff = max(abs_value_es_diff,\n",
    "                                max(abs(np.min(diff_expected_snowfall[i_model].data)),\n",
    "                                        abs(np.max(diff_expected_snowfall[i_model].data))\n",
    "                                   )\n",
    "                               ) /2\n",
    "    \n",
    "   \n",
    "    vmin_freq_diff = -abs_value_freq_diff\n",
    "    vmax_freq_diff = abs_value_freq_diff\n",
    "    \n",
    "   \n",
    "    vmin_es_diff = -abs_value_es_diff\n",
    "    vmax_es_diff = abs_value_es_diff\n",
    "\n",
    "    label_frequency = 'days with daily snowfall > baseline'\n",
    "    label_frequency_diff = 'difference of '+label_frequency \n",
    "    label_es = 'expected excess snowfall > baseline (mm)'\n",
    "    label_es_diff = 'difference of '+label_es\n",
    "                                \n",
    "    fig, fig_axs = plt.subplots(ncols=3, nrows=number_of_models,figsize=(20,20))\n",
    "    gs = fig_axs[0, 0].get_gridspec()\n",
    "    # remove the underlying axes\n",
    "    for i in range(0,3):\n",
    "        for ax in fig_axs[0:, i]:\n",
    "            ax.remove()\n",
    "   \n",
    "    \n",
    "    suptitle = str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > \\n baseline '+str(quantile)+' percentile'\n",
    "\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "                                \n",
    "    for i in range(0,number_of_models):                            \n",
    "        i_model=modellist[i]\n",
    "        modelname=str(i_model)\n",
    "        fig.add_subplot(gs[i, 0])\n",
    "        plot_cube(baseline[i_model],1851,1880,quantile,vmin_base,vmax_base,label_baseline)\n",
    "        plt.title(str(modelname)+' - '+ 'baseline '+str(quantile)+' percentile (historical, 1851-1880)')\n",
    "\n",
    "        fig.add_subplot(gs[i, 1])\n",
    "        plot_difference_cube(diff_frequency[i_model],scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_freq_diff,vmax_freq_diff,label_frequency_diff)\n",
    "    \n",
    "        \n",
    "        fig.add_subplot(gs[i, 2])\n",
    "   \n",
    "        plot_difference_cube(diff_expected_snowfall[i_model],scenario,start_year,final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_es_diff,vmax_es_diff,label_es_diff)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = 'quantile_comparison_maps_'+str(quantile)+'_'+str(areaname)+'_'+reference_scenario+'_'+str(reference_start_year)+\"_\"+str(reference_final_year)+'_vs_'+scenario+'_'+str(start_year)+\"_\"+str(final_year)\n",
    "\n",
    "    plt.savefig(filename+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test of histogram design\n",
    "\n",
    "\n",
    "x = np.random.rand(1000,1)*100\n",
    "y= np.random.rand(2000,1)*100\n",
    "\n",
    "\n",
    "\n",
    "def plot_histograms_comparison_extremes (data,label_data,reference_data,label_ref,label_diff,min_value,max_value,number_of_bins,diffcolor):\n",
    "    \n",
    "    bin_min = min_value\n",
    "    bin_max =  max_value\n",
    "    \n",
    "    all_data_len = len(data)\n",
    "    all_ref_len =len(reference_data)\n",
    "    data = data[data<max_value]\n",
    "    reference_data = reference_data[reference_data<max_value]\n",
    "    \n",
    "    data = data[min_value<data]\n",
    "    reference_data = reference_data[min_value<reference_data]\n",
    "    \n",
    "    weights = np.ones_like(data) / all_data_len\n",
    "\n",
    "    ref_weights = np.ones_like(reference_data) / all_ref_len\n",
    "    \n",
    "    \n",
    "    stepsize = abs(bin_max-bin_min)/number_of_bins\n",
    "    \n",
    "    bins = np.arange (bin_min,bin_max+stepsize,stepsize)\n",
    "   \n",
    "    histogram = plt.hist(data, bins=bins ,label=label_data,weights=weights)\n",
    "    \n",
    "    ref_histogram = plt.hist(reference_data, bins=bins, label=label_ref,weights=ref_weights)\n",
    "    diff =(histogram[0]-ref_histogram[0])\n",
    "    plt.plot(bins[0:len(diff)],diff,color=diffcolor,label=label_diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "plot_histograms_comparison_extremes(x,'x',y,'y','x-y',0,100,100,'navy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def ensemble_average(modellist,data):\n",
    "        average = data [modellist[0]]\n",
    "        number_of_models = len(modellist)\n",
    "        for i in range(1,number_of_models):\n",
    "            average+= data[modellist[i]]\n",
    "        return average / number_of_models\n",
    "    \n",
    "def concatenate_cube_dict (cubedict):\n",
    "    keys = list(cubedict.keys())\n",
    "    start_cube = cubedict [keys[0]]\n",
    "    number_cubes = len(keys)\n",
    "    for i in range(1,number_cubes):\n",
    "        \n",
    "        cube_list = iris.cube.CubeList([start_cube, cubedict[keys[i]]])\n",
    "        start_cube = cube_list.concatenate()[0]\n",
    "        \n",
    "    return start_cube\n",
    "    \n",
    "def ensemble_average_quantile_baseline (quantile,modellist,results,scenario,start_years,\n",
    "                                      timeperiod_length,reference_scenario,reference_start_year,\n",
    "                                      reference_final_year,areaname,maps=True,histograms=True,quantile_ratios=True):\n",
    "    reference_data = {}\n",
    "    data = {}\n",
    "    baseline = {}\n",
    "    quantile_dict={}\n",
    "    ref_exceedances = {}\n",
    "    ref_frequency = {}\n",
    "    ref_expected_snowfall = {}\n",
    "    data_exceedances = {}\n",
    "    data_frequency= {}\n",
    "    data_expected_snowfall= {}\n",
    "    diff_frequency= {}\n",
    "    diff_expected_snowfall= {}\n",
    "    diff_ratios = {}\n",
    "    \n",
    "    \n",
    "    number_of_models = len(modellist)\n",
    "    number_of_timeperiods = len(start_years)\n",
    "    \n",
    "    baseline_key=\"quantile_baseline\"\n",
    "    quantile_key = \"quantile\"\n",
    "    exceedance_key= \"exceedance\"\n",
    "    frequency_key= 'number_exceedances'\n",
    "    mean_exceedance_key= 'mean_exceedance'\n",
    "      \n",
    "    label_baseline = str(quantile)+\" percentile of daily snowfall (mm)\"\n",
    "    \n",
    "    \n",
    "    vmin_base = 0\n",
    "    vmax_base = 0\n",
    "    \n",
    "    abs_value_freq_diff = 0\n",
    "    \n",
    "    abs_value_es_diff = 0\n",
    "    \n",
    "    \n",
    "    baseline_average= {}\n",
    "    quantile_average ={}\n",
    "    quantile_baseline_ratio = {}\n",
    "    \n",
    "    expected_snowfall_ratio = {}\n",
    "    ref_frequency_average= {}\n",
    "    ref_expected_snowfall_average = {}\n",
    "    data_frequency_average= {}\n",
    "    data_expected_snowfall_average= {}\n",
    "    diff_frequency_average = {}\n",
    "    diff_expected_snowfall_average= {}\n",
    "    diff_expected_snowfall_average_relative = {}\n",
    "    ref_ensemble_exceedances = {}\n",
    "    data_ensemble_exceedances = {}\n",
    "    for i_start_year in start_years:\n",
    "        start_year = i_start_year\n",
    "        final_year = start_year+timeperiod_length-1\n",
    "        for i_model in modellist:\n",
    "            reference_data [i_model] = quantile_collection(results[i_model],\n",
    "                                                   reference_scenario,reference_start_year,\n",
    "                                                   reference_final_year,timeperiod_length)\n",
    "            data [i_model] = quantile_collection(results[i_model],scenario,start_year,final_year,\n",
    "                                         timeperiod_length)\n",
    "            baseline [i_model]=reference_data[i_model]['quantiles'][baseline_key,quantile]\n",
    "            quantile_dict [i_model] = data[i_model]['quantiles'][quantile_key,quantile]\n",
    "            ref_exceedances [i_model]= reference_data[i_model]['quantiles'][exceedance_key,quantile]\n",
    "            ref_exceedances [i_model].data = ref_exceedances [i_model].data \n",
    "            ref_frequency [i_model] = reference_data[i_model]['quantiles'][frequency_key,quantile]\n",
    "            ref_expected_snowfall [i_model]=reference_data[i_model]['quantiles'][mean_exceedance_key,quantile]\n",
    "            \n",
    "            \n",
    "            \n",
    "            data_exceedances[i_model]=data[i_model]['quantiles'][exceedance_key,quantile]\n",
    "            data_exceedances [i_model].data = data_exceedances [i_model].data\n",
    "            data_frequency [i_model] = data[i_model]['quantiles'][frequency_key,quantile]\n",
    "            data_expected_snowfall [i_model]=data[i_model]['quantiles'][mean_exceedance_key,quantile]\n",
    "            diff_frequency [i_model] = data_frequency[i_model]-ref_frequency[i_model]\n",
    "            diff_expected_snowfall [i_model] = data_expected_snowfall[i_model]-ref_expected_snowfall[i_model]\n",
    "\n",
    "            vmax_base = max(vmax_base,np.max(baseline [i_model].data) ) /2\n",
    "\n",
    "            abs_value_freq_diff = max(abs_value_freq_diff\n",
    "                                      ,max(abs(np.min(diff_frequency[i_model].data)),\n",
    "                                           abs(np.max(diff_frequency[i_model].data)))\n",
    "                                     )\n",
    "\n",
    "            abs_value_es_diff = max(abs_value_es_diff,\n",
    "                                    max(abs(np.min(diff_expected_snowfall[i_model].data)),\n",
    "                                            abs(np.max(diff_expected_snowfall[i_model].data))\n",
    "                                       )\n",
    "                                   ) /2\n",
    "        baseline_average[i_start_year]= ensemble_average(modellist,baseline)\n",
    "        quantile_average[i_start_year]= ensemble_average(modellist,quantile_dict)\n",
    "        quantile_baseline_ratio [i_start_year] = quantile_average[i_start_year] / baseline_average[i_start_year]\n",
    "       \n",
    "        ref_frequency_average[i_start_year]= ensemble_average(modellist,ref_frequency)\n",
    "        ref_expected_snowfall_average[i_start_year] = ensemble_average(modellist,ref_expected_snowfall)\n",
    "        data_frequency_average[i_start_year] = ensemble_average(modellist,data_frequency)\n",
    "        data_expected_snowfall_average[i_start_year] = ensemble_average(modellist,data_expected_snowfall)\n",
    "        diff_frequency_average[i_start_year] = data_frequency_average[i_start_year] - ref_frequency_average[i_start_year]\n",
    "        diff_expected_snowfall_average[i_start_year] = (data_expected_snowfall_average[i_start_year] - ref_expected_snowfall_average[i_start_year])\n",
    "        diff_expected_snowfall_average_relative[i_start_year] = diff_expected_snowfall_average[i_start_year]/baseline_average[i_start_year]\n",
    "        \n",
    "        \n",
    "       \n",
    "        expected_snowfall_ratio [i_start_year] = data_expected_snowfall_average[i_start_year] / ref_expected_snowfall_average[i_start_year]\n",
    "       \n",
    "        # copy cube to avoid problems with units\n",
    "        diff_ratios [i_start_year] = expected_snowfall_ratio[i_start_year].copy()\n",
    "        (diff_ratios [i_start_year]).data = (expected_snowfall_ratio [i_start_year]).data- (quantile_baseline_ratio [i_start_year]).data\n",
    "        \n",
    "        ref_ensemble_exceedances [i_start_year] = concatenate_cube_dict(ref_exceedances)\n",
    "        data_ensemble_exceedances [i_start_year] = concatenate_cube_dict(data_exceedances)\n",
    "        \n",
    "       \n",
    "        # mask outliers from relative values caused by almost 0 baseline:\n",
    "        to_mask = diff_expected_snowfall_average_relative[i_start_year].data\n",
    "        diff_expected_snowfall_average_relative[i_start_year].data = np.ma.masked_where(np.abs(to_mask) >= 2, to_mask)\n",
    "       \n",
    "        \n",
    "        vmax_base = max(vmax_base,np.max(baseline_average[i_start_year].data) /2)\n",
    "        abs_value_freq_diff = max(abs_value_freq_diff,max(abs(np.min(diff_frequency_average[i_start_year].data)),\n",
    "                                        abs(np.max(diff_frequency_average[i_start_year].data))))\n",
    "        abs_value_es_diff = max(abs_value_es_diff,max(abs(np.min(diff_expected_snowfall_average[i_start_year].data)),\n",
    "                                        abs(np.max(diff_expected_snowfall_average[i_start_year].data))))\n",
    "        \n",
    "        abs_value_es_diff_rel = 1\n",
    "\n",
    "\n",
    "\n",
    "    vmin_freq_diff = -abs_value_freq_diff\n",
    "    vmax_freq_diff = abs_value_freq_diff\n",
    "\n",
    "\n",
    "    vmin_es_diff = -abs_value_es_diff\n",
    "    vmax_es_diff = abs_value_es_diff\n",
    "    \n",
    "    vmin_es_diff_rel = -abs_value_es_diff_rel\n",
    "    vmax_es_diff_rel = abs_value_es_diff_rel \n",
    "    \n",
    "\n",
    "\n",
    "    label_frequency = 'days with daily snowfall > baseline'\n",
    "    label_frequency_diff = 'difference of '+label_frequency \n",
    "    label_es = 'expected excess snowfall > baseline (mm)'\n",
    "    label_es_diff = 'difference of '+label_es\n",
    "    \n",
    "    \n",
    "    \n",
    "    label_es_diff_relative = 'baseline relative '+label_es_diff\n",
    "\n",
    "    \n",
    "    label_quantile_ratio='ratio of percentile / baseline percentile'\n",
    "    label_es_ratio='ratio of expected extreme snowfall (EES) / baseline EES'\n",
    "    \n",
    "\n",
    "    label_ratio_diff = \"difference of percentile and expected snofall to resp. baseline ratio\"\n",
    "\n",
    "    modelname='ISIMIP_3b_primary_model_average'\n",
    "   \n",
    "    if (quantile_ratios):\n",
    "\n",
    "        fig, fig_axs = plt.subplots(ncols=3, nrows=number_of_timeperiods,figsize=(18,4*number_of_timeperiods))\n",
    "        gs = fig_axs[0, 0].get_gridspec()\n",
    "        # remove the underlying axes\n",
    "        for i in range(0,3):\n",
    "            for ax in fig_axs[0:, i]:\n",
    "                ax.remove()\n",
    "        for i in range (0,number_of_timeperiods):\n",
    "\n",
    "           \n",
    "            final_year = start_years[i]+timeperiod_length-1\n",
    "            fig.add_subplot(gs[i, 0])\n",
    "            plot_ratio_cube(quantile_baseline_ratio[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,label_quantile_ratio)\n",
    "\n",
    "\n",
    "            fig.add_subplot(gs[i, 1])\n",
    "\n",
    "            plot_ratio_cube(expected_snowfall_ratio[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,label_es_ratio)\n",
    "\n",
    "            fig.add_subplot(gs[i, 2])\n",
    "\n",
    "            plot_difference_cube(diff_ratios[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,-2,2,label_ratio_diff)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        filename = 'quantile_baseline_ratio_maps_'+str(quantile)+'_'+str(areaname)+'_'+reference_scenario+'_vs_'+scenario+'_'+str(start_years[0])+'_'+str(final_year)\n",
    "        suptitle = str(modelname)+ \" - \"+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n  ratio to baseline '+str(quantile)+' percentile'\n",
    "        fig.subplots_adjust(top=0.875)\n",
    "        plt.suptitle(suptitle,y=0.95)\n",
    "\n",
    "\n",
    "        plt.savefig(filename+'.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if(maps):\n",
    "        fig, fig_axs = plt.subplots(ncols=3, nrows=number_of_timeperiods,figsize=(18,4*number_of_timeperiods))\n",
    "        gs = fig_axs[0, 0].get_gridspec()\n",
    "        # remove the underlying axes\n",
    "        for i in range(0,3):\n",
    "            for ax in fig_axs[0:, i]:\n",
    "                ax.remove()\n",
    "        for i in range (0,number_of_timeperiods):\n",
    "\n",
    "            #fig.add_subplot(gs[i, 0])\n",
    "            #plot_cube(baseline_average[i_start_year],1851,1880,quantile,vmin_base,vmax_base,label_baseline)\n",
    "            #plt.title(str(modelname)+' - '+ 'baseline '+str(quantile)+' percentile (historical, 1851-1880)')\n",
    "            final_year = start_years[i]+timeperiod_length-1\n",
    "            fig.add_subplot(gs[i, 0])\n",
    "            plot_difference_cube(diff_frequency_average[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_freq_diff,vmax_freq_diff,label_frequency_diff)\n",
    "\n",
    "\n",
    "            fig.add_subplot(gs[i, 1])\n",
    "\n",
    "            plot_difference_cube(diff_expected_snowfall_average[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_es_diff,vmax_es_diff,label_es_diff)\n",
    "\n",
    "            fig.add_subplot(gs[i, 2])\n",
    "\n",
    "            plot_difference_cube(diff_expected_snowfall_average_relative[start_years[i]],scenario,start_years[i],final_year,reference_scenario,reference_start_year,reference_final_year,quantile,vmin_es_diff_rel,vmax_es_diff_rel,label_es_diff_relative)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        filename = 'quantile_ensemble_average_maps_'+str(quantile)+'_'+str(areaname)+'_'+reference_scenario+'_vs_'+scenario+'_'+str(start_years[0])+'_'+str(final_year)\n",
    "        suptitle = str(modelname)+ \" - \"+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > \\n baseline '+str(quantile)+' percentile'\n",
    "        fig.subplots_adjust(top=0.875)\n",
    "        plt.suptitle(suptitle,y=0.95)\n",
    "\n",
    "        \n",
    "        plt.savefig(filename+'.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    if(histograms):\n",
    "        fig2, fig2_axs = plt.subplots(ncols=3, nrows=number_of_timeperiods,figsize=(20,8*number_of_timeperiods))\n",
    "        gs = fig2_axs[0, 0].get_gridspec()\n",
    "        # remove the underlying axes\n",
    "        for i in range(0,3):\n",
    "            for ax in fig2_axs[0:, i]:\n",
    "                ax.remove()\n",
    "\n",
    "        hist_comparison_title = 'percentile exceedance (mm), \\n relative share of total days'\n",
    "\n",
    "        for i in range (0,number_of_timeperiods):\n",
    "\n",
    "            final_year = start_years[i]+timeperiod_length-1\n",
    "\n",
    "            fig2.add_subplot(gs[i, 0])\n",
    "\n",
    "            data_exceedances = data_ensemble_exceedances [start_years[i]].data.flatten()\n",
    "            ref_exceedances = ref_ensemble_exceedances[start_years[i]].data.flatten()\n",
    "            plot_histograms_comparison_extremes (data_exceedances,scenario,ref_exceedances,reference_scenario,'ssp - hist',10,500,100,'darkred')\n",
    "            plt.legend()\n",
    "            plt.title(hist_comparison_title + '\\n '+scenario+ \":\"+str(start_years[i]) + ' to '+str(final_year) +'\\n '+reference_scenario+ \":\"+str(reference_start_year) + ' to '+str(reference_final_year))\n",
    "\n",
    "            fig2.add_subplot(gs[i, 1])\n",
    "\n",
    "\n",
    "            plot_histograms_comparison_extremes (data_exceedances,scenario,ref_exceedances,reference_scenario,'ssp - hist',500,1000,100,'darkred')\n",
    "            plt.legend()\n",
    "            plt.title(hist_comparison_title + '\\n '+scenario+ \":\"+str(start_years[i]) + ' to '+str(final_year) +'\\n '+reference_scenario+ \":\"+str(reference_start_year) + ' to '+str(reference_final_year))\n",
    "\n",
    "\n",
    "            fig2.add_subplot(gs[i, 2])\n",
    "\n",
    "\n",
    "            plot_histograms_comparison_extremes (data_exceedances,scenario,ref_exceedances,reference_scenario,'ssp - hist',1000,2000,100,'darkred')\n",
    "            plt.legend()\n",
    "            plt.title(hist_comparison_title + '\\n '+scenario+ \":\"+str(start_years[i]) + ' to '+str(final_year) +'\\n '+reference_scenario+ \":\"+str(reference_start_year) + ' to '+str(reference_final_year))\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        filename = 'quantile_ensemble_histograms_'+str(quantile)+'_'+str(areaname)+'_'+reference_scenario+'_vs_'+scenario+str(start_years[0])+'_'+str(final_year)\n",
    "        suptitle = str(modelname)+ \" - \"+str(areaname)+'- \\n'+scenario+ ' versus '+reference_scenario+'\\n comparison  of daily snowfall > \\n baseline '+str(quantile)+' percentile'\n",
    "\n",
    "        fig2.subplots_adjust(top=0.875)\n",
    "        plt.suptitle(suptitle,y=0.95)\n",
    "        plt.savefig(filename+'.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "        plt.close() \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "modellist = [\n",
    "'gfdl-esm4',\n",
    "'ipsl-cm6a-lr',\n",
    "'mpi-esm1-2-hr',\n",
    "'mri-esm2-0',\n",
    "'ukesm1-0-ll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_quantile_average (modellist,all_results,comparisonname,areaname,start_years,maps=True,histograms=True, quantile_ratios=True):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "    \n",
    "    ensemble = 'ISIMIP3b primary models' \n",
    "    quantiles = [99,99.73,99.9]\n",
    "    scenarios = ['ssp585']\n",
    "    reference_scenarios = ['historical']\n",
    "    for i_quantile in quantiles:\n",
    "        for i_scenario in scenarios:\n",
    "            for i_reference_scenario in reference_scenarios:\n",
    "             \n",
    "                \n",
    "                    # decadal plots\n",
    "              \n",
    "                ensemble_average_quantile_baseline(i_quantile,modellist,ensemble_results,i_scenario,start_years,10,\n",
    "                        i_reference_scenario,1851,1880,areaname,maps=maps,histograms=histograms, quantile_ratios=quantile_ratios)\n",
    "               \n",
    "                \n",
    "                #start_years =[2051,2061,2071,2081,2091]\n",
    "                    # decadal plots\n",
    "              \n",
    "                #ensemble_average_quantile_baseline(i_quantile,modellist,ensemble_results,i_scenario,start_years,10,\n",
    "                       # i_reference_scenario,1851,1880,areaname,maps=maps)\n",
    "               \n",
    "                \n",
    "            \n",
    "               \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "              \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quante/.conda/envs/my_root/lib/python3.6/site-packages/iris/coords.py:1193: UserWarning: Coordinate 'longitude' is not bounded, guessing contiguous bounds.\n",
      "  'contiguous bounds.'.format(self.name()))\n",
      "/home/quante/.conda/envs/my_root/lib/python3.6/site-packages/iris/coords.py:1193: UserWarning: Coordinate 'latitude' is not bounded, guessing contiguous bounds.\n",
      "  'contiguous bounds.'.format(self.name()))\n",
      "/home/quante/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n",
      "/home/quante/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/io/__init__.py:260: DownloadWarning: Downloading: http://naciscdn.org/naturalearth/110m/physical/ne_110m_coastline.zip\n",
      "  warnings.warn('Downloading: {}'.format(url), DownloadWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-38-cfebda7f0550>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mstart_years\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2021\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2031\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2041\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mnorthern_america\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mensemble_quantile_average\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmodellist\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mall_results\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'preindustrial'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'NORTHERN AMERICA'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstart_years\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mmaps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhistograms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquantile_ratios\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-22-514be7e5b28f>\u001B[0m in \u001B[0;36mensemble_quantile_average\u001B[0;34m(modellist, all_results, comparisonname, areaname, start_years, maps, histograms, quantile_ratios)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m                 ensemble_average_quantile_baseline(i_quantile,modellist,ensemble_results,i_scenario,start_years,10,\n\u001B[0;32m---> 18\u001B[0;31m                         i_reference_scenario,1851,1880,areaname,maps=maps,histograms=histograms, quantile_ratios=quantile_ratios)\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-20-00bc4e7f818f>\u001B[0m in \u001B[0;36mensemble_average_quantile_baseline\u001B[0;34m(quantile, modellist, results, scenario, start_years, timeperiod_length, reference_scenario, reference_start_year, reference_final_year, areaname, maps, histograms, quantile_ratios)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 210\u001B[0;31m        \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msavefig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m'.png'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdpi\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m300\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbbox_inches\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'tight'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    211\u001B[0m        \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    212\u001B[0m        \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/pyplot.py\u001B[0m in \u001B[0;36msavefig\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msavefig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m     \u001B[0mfig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgcf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 689\u001B[0;31m     \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msavefig\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    690\u001B[0m     \u001B[0mfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw_idle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m   \u001B[0;31m# need this if 'transparent=True' to reset colors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/figure.py\u001B[0m in \u001B[0;36msavefig\u001B[0;34m(self, fname, frameon, transparent, **kwargs)\u001B[0m\n\u001B[1;32m   2092\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_frameon\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframeon\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2093\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2094\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcanvas\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprint_figure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2095\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2096\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mframeon\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001B[0m in \u001B[0;36mprint_figure\u001B[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001B[0m\n\u001B[1;32m   2047\u001B[0m                         \u001B[0morientation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morientation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2048\u001B[0m                         \u001B[0mdryrun\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2049\u001B[0;31m                         **kwargs)\n\u001B[0m\u001B[1;32m   2050\u001B[0m                     \u001B[0mrenderer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cachedRenderer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2051\u001B[0m                     \u001B[0mbbox_artists\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"bbox_extra_artists\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001B[0m in \u001B[0;36mprint_png\u001B[0;34m(self, filename_or_obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m         \"\"\"\n\u001B[0;32m--> 510\u001B[0;31m         \u001B[0mFigureCanvasAgg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    511\u001B[0m         \u001B[0mrenderer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_renderer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001B[0m in \u001B[0;36mdraw\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    400\u001B[0m         \u001B[0mtoolbar\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoolbar\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    401\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 402\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    403\u001B[0m             \u001B[0;31m# A GUI class may be need to update a window using this draw, so\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    404\u001B[0m             \u001B[0;31m# don't forget to call the superclass.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0martist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/figure.py\u001B[0m in \u001B[0;36mdraw\u001B[0;34m(self, renderer)\u001B[0m\n\u001B[1;32m   1647\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1648\u001B[0m             mimage._draw_list_compositing_images(\n\u001B[0;32m-> 1649\u001B[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001B[0m\u001B[1;32m   1650\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1651\u001B[0m             \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'figure'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/image.py\u001B[0m in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mnot_composite\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhas_images\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0martists\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 138\u001B[0;31m             \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    139\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;31m# Composite any adjacent images together\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0martist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/mpl/geoaxes.py\u001B[0m in \u001B[0;36mdraw\u001B[0;34m(self, renderer, inframe)\u001B[0m\n\u001B[1;32m    383\u001B[0m                 self.imshow(img, extent=extent, origin=origin,\n\u001B[1;32m    384\u001B[0m                             transform=factory.crs, *args[1:], **kwargs)\n\u001B[0;32m--> 385\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_done_img_factory\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    386\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m         return matplotlib.axes.Axes.draw(self, renderer=renderer,\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0martist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001B[0m in \u001B[0;36mdraw\u001B[0;34m(self, renderer, inframe)\u001B[0m\n\u001B[1;32m   2626\u001B[0m             \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_rasterizing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2627\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2628\u001B[0;31m         \u001B[0mmimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_draw_list_compositing_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0martists\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2629\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2630\u001B[0m         \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'axes'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/image.py\u001B[0m in \u001B[0;36m_draw_list_compositing_images\u001B[0;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mnot_composite\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhas_images\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    137\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0martists\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 138\u001B[0;31m             \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    139\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;31m# Composite any adjacent images together\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/matplotlib/artist.py\u001B[0m in \u001B[0;36mdraw_wrapper\u001B[0;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0mrenderer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstart_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mdraw\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0martist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrenderer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0martist\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_agg_filter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/mpl/feature_artist.py\u001B[0m in \u001B[0;36mdraw\u001B[0;34m(self, renderer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_zorder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'zorder'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 137\u001B[0;31m             \u001B[0;31m# The class attribute matplotlib.collections.PathCollection.zorder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    138\u001B[0m             \u001B[0;31m# was removed after mpl v1.2.0, so the hard-coded value of 1 is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0;31m# used instead.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/feature.py\u001B[0m in \u001B[0;36mintersecting_geometries\u001B[0;34m(self, extent)\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/feature.py\u001B[0m in \u001B[0;36mgeometries\u001B[0;34m(self)\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/io/shapereader.py\u001B[0m in \u001B[0;36mnatural_earth\u001B[0;34m(resolution, category, name)\u001B[0m\n\u001B[1;32m    263\u001B[0m     \"\"\"\n\u001B[1;32m    264\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbbox\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 265\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    266\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mfiona\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/io/__init__.py\u001B[0m in \u001B[0;36mpath\u001B[0;34m(self, format_dict)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0;31m# we need to download the file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m             \u001B[0mresult_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire_resource\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/io/shapereader.py\u001B[0m in \u001B[0;36macquire_resource\u001B[0;34m(self, target_path, format_dict)\u001B[0m\n\u001B[1;32m    318\u001B[0m         \"\"\"\n\u001B[1;32m    319\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m             yield FionaRecord(item['geometry'],\n\u001B[0m\u001B[1;32m    321\u001B[0m                               {key: value for key, value in\n\u001B[1;32m    322\u001B[0m                                item.items() if key != 'geometry'})\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/site-packages/cartopy/io/__init__.py\u001B[0m in \u001B[0;36m_urlopen\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    259\u001B[0m         \"\"\"\n\u001B[1;32m    260\u001B[0m         \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Downloading: {}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDownloadWarning\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 261\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[1;32m    221\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m         \u001B[0mopener\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 223\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopener\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    224\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0minstall_opener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[1;32m    524\u001B[0m             \u001B[0mreq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmeth\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    525\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 526\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    527\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    528\u001B[0m         \u001B[0;31m# post-process response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, req, data)\u001B[0m\n\u001B[1;32m    542\u001B[0m         \u001B[0mprotocol\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    543\u001B[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001B[0;32m--> 544\u001B[0;31m                                   '_open', req)\n\u001B[0m\u001B[1;32m    545\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    546\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36m_call_chain\u001B[0;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[1;32m    502\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhandler\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mhandlers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    503\u001B[0m             \u001B[0mfunc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeth_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 504\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    505\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36mhttp_open\u001B[0;34m(self, req)\u001B[0m\n\u001B[1;32m   1344\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1345\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mhttp_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1346\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHTTPConnection\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1347\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1348\u001B[0m     \u001B[0mhttp_request\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAbstractHTTPHandler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_request_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/urllib/request.py\u001B[0m in \u001B[0;36mdo_open\u001B[0;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1317\u001B[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001B[0;32m-> 1318\u001B[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001B[0m\u001B[1;32m   1319\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# timeout error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mURLError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1237\u001B[0m                 encode_chunked=False):\n\u001B[1;32m   1238\u001B[0m         \u001B[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1239\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_send_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1240\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1241\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_send_request\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36m_send_request\u001B[0;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[1;32m   1283\u001B[0m             \u001B[0;31m# default charset of iso-8859-1.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1284\u001B[0m             \u001B[0mbody\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_encode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'body'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1285\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mendheaders\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1286\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1287\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36mendheaders\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1232\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1233\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mCannotSendHeader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1234\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_send_output\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage_body\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencode_chunked\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencode_chunked\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1235\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1236\u001B[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36m_send_output\u001B[0;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[1;32m   1024\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mb\"\\r\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1025\u001B[0m         \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1026\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1027\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1028\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmessage_body\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    962\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msock\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_open\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 964\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    965\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mNotConnected\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/http/client.py\u001B[0m in \u001B[0;36mconnect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    934\u001B[0m         \u001B[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m         self.sock = self._create_connection(\n\u001B[0;32m--> 936\u001B[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001B[0m\u001B[1;32m    937\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetsockopt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIPPROTO_TCP\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTCP_NODELAY\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    938\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/my_root/lib/python3.6/socket.py\u001B[0m in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address)\u001B[0m\n\u001B[1;32m    711\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0msource_address\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    712\u001B[0m                 \u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource_address\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 713\u001B[0;31m             \u001B[0msock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconnect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msa\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    714\u001B[0m             \u001B[0;31m# Break explicitly a reference cycle\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    715\u001B[0m             \u001B[0merr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "plt.close()\n",
    "start_years =[2021,2031,2041]\n",
    "northern_america = ensemble_quantile_average (modellist,all_results,'preindustrial','NORTHERN AMERICA',start_years,maps=True, histograms=False, quantile_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_years =[2021,2031,2041]\n",
    "northern_europe = ensemble_quantile_average (modellist,eu_all_results,'preindustrial','NORTHERN EUROPE',start_years,maps=False,histograms=False, quantile_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_years =[2051,2061,2071]\n",
    "\n",
    "\n",
    "midterm_america = ensemble_quantile_average (modellist,midterm_all_results,'preindustrial','NORTHERN AMERICA',start_years,maps=False, histograms=False, quantile_ratios=True)\n",
    "midterm_europe = ensemble_quantile_average (modellist,midterm_all_results,'preindustrial','NORTHERN EUROPE',start_years,maps=False, histograms=False, quantile_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_years =[2071,2081,2091]\n",
    "\n",
    "longterm_america = ensemble_quantile_average (modellist,longterm_all_results,'preindustrial','NORTHERN AMERICA',start_years,maps=False, histograms=False, quantile_ratios=True)\n",
    "longterm_europe = ensemble_quantile_average (modellist,longterm_all_results,'preindustrial','NORTHERN EUROPE',start_years,maps=False, histograms=False, quantile_ratios=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_simulation_maps (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "    \n",
    "    ensemble = 'ISIMIP3b primary models' \n",
    "    thresholds = [500,750,1000,1250,1500]\n",
    "   \n",
    "    for i_threshold in thresholds:\n",
    "         # shortterm plots\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "                'historical',1851,1880,areaname)   \n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "                'historical',1851,1880,areaname) \n",
    "\n",
    "        # longterm plots\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp126',2051,2100,areaname)\n",
    "        compare_timespans_threshold_maps(i_threshold,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp370',2051,2100,areaname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_simulation_quantile_maps (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "    \n",
    "    ensemble = 'ISIMIP3b primary models' \n",
    "    quantiles = [99,99.73,99.9]\n",
    "    \n",
    "   \n",
    "    for i_quantile in quantiles:\n",
    "         # shortterm plots\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "\n",
    "        # longterm plots\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp126',2051,2100,areaname)\n",
    "        compare_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp370',2051,2100,areaname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_quantile_comparison (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "    \n",
    "    ensemble = 'ISIMIP3b primary models' \n",
    "    quantiles = [99,99.73,99.9]\n",
    "    \n",
    "   \n",
    "    for i_quantile in quantiles:\n",
    "         # shortterm plots\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "\n",
    "        # longterm plots\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp126',2051,2100,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp370',2051,2100,areaname)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_simulation (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "\n",
    "    ensemble = 'ISIMIP3b primary models'    \n",
    "    # shortterm plots\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname)   \n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname) \n",
    "\n",
    "    # longterm plots\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp126',2051,2100,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp370',2051,2100,ensemble,areaname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_simulation (modellist,all_results,'preindustrial','NORTHERN AMERICA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quantiles=[95,99,99.73,99.9,99.99]\n",
    "ensemble_simulation_quantiles (modellist,quantiles,all_results,'preindustrial','NORTHERN AMERICA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_simulation (modellist,all_results,'preindustrial','NORTHERN EUROPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_simulation (modellist,all_results,'preindustrial','NORTHERN EUROPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble_quantile_comparison (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "    \n",
    "    ensemble = 'ISIMIP3b primary models' \n",
    "    quantiles = [99,99.73,99.9]\n",
    "    \n",
    "   \n",
    "    for i_quantile in quantiles:\n",
    "         # shortterm plots\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "\n",
    "        # longterm plots\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "               'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'historical',1851,1880,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp126',2051,2100,areaname)\n",
    "        ensemble_quantile_baseline(i_quantile,modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "                'ssp370',2051,2100,areaname)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_simulation (modellist,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "\n",
    "    ensemble = 'ISIMIP3b primary models'    \n",
    "    # shortterm plots\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2021,2030,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2031,2040,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2041,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname)   \n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2021,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname) \n",
    "\n",
    "    # longterm plots\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp126',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp370',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp126',2051,2100,ensemble,areaname)\n",
    "    compare_timespans_threshold_frequency(modellist,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp370',2051,2100,ensemble,areaname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_simulation (modellist,all_results,'preindustrial','NORTHERN AMERICA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantiles=[95,99,99.73,99.9,99.99]\n",
    "ensemble_simulation_quantiles (modellist,quantiles,all_results,'preindustrial','NORTHERN AMERICA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_simulation (modellist,all_results,'preindustrial','NORTHERN EUROPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ensemble_simulation_quantiles (modellist,quantiles,all_results,comparisonname,areaname):\n",
    "    ensemble_results ={}\n",
    "    for i_model in modellist:\n",
    "        ensemble_results [i_model]=specify_results(all_results,i_model,comparisonname,areaname)\n",
    "\n",
    "    ensemble = 'ISIMIP3b primary models'    \n",
    "    # shortterm plots\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2021,2030,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2031,2040,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2041,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname)   \n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2021,2050,10,\n",
    "            'historical',1851,1880,ensemble,areaname) \n",
    "\n",
    "    # longterm plots\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp126',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp370',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'historical',1851,1880,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp126',2051,2100,ensemble,areaname)\n",
    "    compare_timespans_quantiles(modellist,quantiles,ensemble_results,'ssp585',2051,2100,10,\n",
    "            'ssp370',2051,2100,ensemble,areaname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_root)",
   "language": "python",
   "name": "my_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}