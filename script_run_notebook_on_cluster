#!/bin/bash

#SBATCH --qos=priority
#SBATCH --job-name=jupyter_launch
#SBATCH --account=acclimat
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=60000
#SBATCH --time=24:00:00
#SBATCH --output=jupyter-%j.log

###
# This script is to submitted via "sbatch" on the cluster.
#
# Set --cpus-per-task above to match the size of your multiprocessing run, if any.
# Thanks to Ciaron Linstead @PIK for providing this script
###

echo "------------------------------------------------------------"
echo "SLURM JOB ID: $SLURM_JOBID"
echo "Running on nodes: $SLURM_NODELIST"
echo "------------------------------------------------------------"

# Some initial setup
export I_MPI_PMI_LIBRARY=/p/system/slurm/lib/libpmi.so
module purge
module load anaconda/5.0.0_py3 # this is where the Jupyter client comes from

## set the port on which the notebook server will listen
NOTEBOOKPORT=8888

# set a random port for the notebook, in case multiple notebooks are
# on the same compute node.
NOTEBOOKPORT=$(shuf -i 8000-8500 -n 1)

# set a random port for tunneling, in case multiple connections are happening
# on the same login node.
TUNNELPORT=$(shuf -i 8501-9000 -n 1)

echo "On your local machine, run:"
echo ""
echo "ssh -L8888:localhost:$TUNNELPORT $SLURM_SUBMIT_HOST -N"
echo ""
echo "and point your browser to http://localhost:8888"
echo "Change '8888' to some other value if this port is already in use on your PC,"
echo "for example, you have more than one remote notebook running."
echo "To stop this notebook, run 'scancel $SLURM_JOB_ID'"

# Set up a reverse SSH tunnel from the compute node back to the submitting host (login01 or login02)
# This is the machine we will connect to with SSH forward tunneling from our client.
ssh -R$TUNNELPORT:localhost:$NOTEBOOKPORT $SLURM_SUBMIT_HOST -N -f

# Start the notebook
srun -n1 jupyter-notebook --no-browser --port=$NOTEBOOKPORT

# To stop the notebook, use 'scancel'
